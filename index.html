<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Deep-Learned Pedestrian Avoidance Policy for Robot Navigation</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Deep-Learned Pedestrian Avoidance Policy for Robot Navigation</h1>
      <h2 class="project-tagline"></h2>
    </section>

    <section class="main-content">

<h3>
<a id="summary" class="anchor" href="#background" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Summary</h3>

<p>In this project, we study the pedestrian avoidance and path following problems with the input solely from a monocular camera of a mobile robot. Previous works mainly focused on vision-based approaches to explicitly perform pedestrian detection and path identification; we propose a learning-based approach based on Deep Neural Networks (DNNs) trained on large scale image dataset. By doing so, we cast the two tasks into image classification problems. Preliminary results show that our approach outperforms the alternative vision-based solution with more robustness and generality. 
</p>
   
<h3>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background</h3>

<p>Autonomous navigation and collision avoidance are challenging and still remain unsolved for robotics. Solutions to such problems are essential to many robotic applications including service robots, Last-Mile-Delivery and postdisaster search and rescue. In order to successfully navigate along a path and avoid pedestrians at the same time, the robot needs to perceive where the path is leading and where the pedestrians are. Based on those information, the robot can then react in order to stay on the path and avoid collision with human beings. In this project, we propose a machine-learning approach to tackle such problems and show preliminary results on an autonomous mobile robot.
</p>

<h3>
<a id="motivation" class="anchor" href="#problem-statement" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Motivation</h3>

<p>
Path following and pedestrian avoidance for mobile robots are extremely difficult tasks yet interesting and rewarding problems to solve. The traditional solutions mainly resort to Computer vision approach using object recognition and motion tracking. The latter is a significantly more difficult problem than the former because the depth information is hard to retrieve without the help of expensive depth sensors. In addition, the prediction accuracy depends heavily on the correctness of object detection and recognition. In this project, we consider Deep Learning technique as an alternative to Computer Vision approach, which maps the vision input directly to the motor output in a so-called End-to-End manner. By doing so, we expect to take advantage of the generality of neural networks.</p>

<h3>
<a id="scope" class="anchor" href="#scope" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Scope</h3>

<p>In this project, we focus on path following and pedestrian avoidance problems for a mobile robot. The problems are restricted to indoor navigation with only a monocular RGB camera as input. However, for safety reasons, the robot will be equipped with distance sensors, for example, ultrasonic sensors, to prevent the robot from colliding with obstacles outside the view of the camera.</p>

<h3>
<a id="video" class="anchor" href="#video" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Demo 1 (open space test)</h3>
<iframe width="640" height="480" src="https://www.youtube.com/embed/ZLBTMXR4nOQ"></iframe>
<br>
<br>
      
<h3>
<a id="video" class="anchor" href="#video" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Demo 2 (corridor test)</h3>
<iframe width="640" height="480" src="https://www.youtube.com/embed/iREEAKCbwRM"></iframe>
<br>
<br>

<h3>
<a id="video" class="anchor" href="#video" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Demo 2 (corridor test, first robot view)</h3>
<iframe width="640" height="480" src="https://www.youtube.com/embed/M8TVwy390tU"></iframe>
<br>
<br>

<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>About Us</h3>

<p>We are two final year CS students, Cao Chao and Hu Shengjie, from the University of Hong Kong (HKU) and we are doing our final year project under the supervision of Prof. Wenping Wang (<a href="http://i.cs.hku.hk/~wenping/" class="user-mention">@WenPing Wang</a>)from the Computer Science Department at HKU.
<br>
<br>
Please contact us at:
<br>
Cao Chao: caochao39@gmail.com<br>
Hu Shengjie: jasonhu515@gmail.com
</p>


      <footer class="site-footer">

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
